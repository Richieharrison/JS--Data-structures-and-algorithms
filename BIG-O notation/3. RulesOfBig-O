The goal of algorithmic analysis is to understand the algorithm's efficiency by calculating f(n).
However, it is challenging to calculate f(n). Hence the following fundamental rules:

# 1. Coefficient rule

If f(n) is O(g(n)), then kf(n) is O(g(n)), for any constant K > 0.
This first rule, eliminates coefficients not related to input size, n. 
This is because as n approaches infinity, the other coefficients become negligible.

# 2. Sum rule

If f(n) is O(h(n)) and g(n) is o(p(n)), then f(n)+g(n) is O(h(n) + p(n)).
The sum rule simply states that if a resultant time complexity is a sum of two different
time complexities, the results Big-O is also the sum of two different Big-O notations

# 3. Product rule

If f(n) is O(h(n)) and g(n) is O(p(n)), then f(n)g(n) is O(h(n)p(n)).
The product rule states that Big-O is multiplied when the time complexities are multiplied.

# 4. Transitive rule

If f(n) is O(g(n)) and g(n) is O(h(n)), then f(n) is O(h(n)). 
This is a simple way to say that the same time complexities has the same Big-O.

# 5. Polynomial rule

If f(n) is a Polynomial of degree k, then f(n) is O(n^k).
It states that Polynomial time complexities have Big-O of the same Polynomial degree.

# 6. Log of a power rule.

log(nk) is O(log(n)) for any constant k > 0. With the log of a power rule, constants within
a log function are also ignored in Big-O

**NB**
Special attention should be paid to the first three rules and the polynomial rule
because they are the most commonly used